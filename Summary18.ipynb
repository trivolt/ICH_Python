{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f6e17f8-ba8d-4655-9309-2787f825ba3c",
   "metadata": {},
   "source": [
    "# Summary18 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b7e5b-cf5a-4ed2-9612-e0057abe16dc",
   "metadata": {},
   "source": [
    "### ДЗ 35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a1a8c9-bd38-48f9-87df-3398ed67f02d",
   "metadata": {},
   "source": [
    "Напишите функцию get_response(url), которая отправляет GET-запрос по заданному URL-адресу и возвращает объект ответа. Затем выведите следующую информацию об ответе:\n",
    "- Код состояния (status code)\n",
    "- Текст ответа (response text)\n",
    "- Заголовки ответа (response headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5532e7d0-c9ae-42bf-8586-a8a7108f445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_response(url):\n",
    "    response = requests.get(\"https://\"+url)\n",
    "    print(response.status_code) \n",
    "    print(response.text)\n",
    "    print(response.headers)\n",
    "\n",
    "address=input()\n",
    "get_response(address)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e97337-4d23-481c-ba1f-846c73589237",
   "metadata": {},
   "source": [
    "2. Напишите функцию find_common_words(url_list), которая принимает список URL-адресов и возвращает список наиболее часто встречающихся слов на веб-страницах. Для каждого URL-адреса функция должна получить содержимое страницы с помощью запроса GET и использовать регулярные выражения для извлечения слов. Затем функция должна подсчитать количество вхождений каждого слова и вернуть наиболее часто встречающиеся слова в порядке убывания частоты.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e72495e-b9ab-44a2-85ef-7271be60aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def find_common_words(url_list):\n",
    "    text=\"\"\n",
    "    for url in url_list:\n",
    "        response = requests.get(\"https://\"+url)\n",
    "        text+= response.text\n",
    "    words = re.findallа(r\"\\b[a-zA-Zа-яА-ЯёЁ]+\\b\",text)\n",
    "    for key,value in Counter(words).most_common(5):\n",
    "        print(f\"{key} {value}\")\n",
    "    \n",
    "find_common_words([\"realpython.com\",\"example.com\",\"pythonru.com\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b306f0c-2249-40e8-8ea9-dbace61536e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# В тетрадке Python_35 представлено решение задачи 2 в более расширенном варианте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f277b92-d6b5-4833-9b89-2a3702abecdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2692d76c-888b-41bd-8351-609a15142159",
   "metadata": {},
   "source": [
    "### ДЗ 36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb64a8a0-f264-40c2-a913-6301cf0e96e6",
   "metadata": {},
   "source": [
    "1. Напишите программу, которая запрашивает у пользователя URL-адрес веб-страницы, использует библиотеку Beautiful Soup для парсинга HTML и выводит список всех ссылок на странице.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c508733-576f-4752-b7f2-11fe94d0e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_links(url):\n",
    "    html = requests.get(\"https://\"+url).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    links = soup.find_all(\"a\")\n",
    "    for i in links:\n",
    "        print(i[\"href\"])\n",
    "\n",
    "address=input(\"Введите адрес страницы: \")\n",
    "get_links(address)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e50067-19f8-4a7a-8178-eb47b0d303de",
   "metadata": {},
   "source": [
    "2. Напишите программу, которая запрашивает у пользователя URL-адрес веб-страницы и уровень заголовков, а затем использует библиотеку Beautiful Soup для парсинга HTML и извлекает заголовки нужного уровня (теги h1, h2, h3 и т.д.) с их текстом.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1f7ed7-4da8-42f5-92b3-39c3c0990ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_headers(url,level):\n",
    "    html = requests.get(\"https://\"+url).text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    headers = soup.find_all(\"h\"+level)\n",
    "    for i in headers:\n",
    "        print(i)\n",
    "\n",
    "address=input(\"Введите адрес страницы: \")\n",
    "level=input(\"Введите уровень заголовка: \")\n",
    "get_headers(address,level)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
